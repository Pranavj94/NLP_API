{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import text_utils\n",
    "import model_utils\n",
    "import configs\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "\n",
    "train=pd.read_csv('./Corona_NLP_train.csv',encoding='latin1')\n",
    "test=pd.read_csv('./Corona_NLP_test.csv')\n",
    "print('Number of training shape',train.shape)\n",
    "print('Number of testing records',test.shape)\n",
    "print('Number of unique labels in train',train['Sentiment'].nunique())\n",
    "print('Number of unique labels in test',test['Sentiment'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeding everything for reproducability\n",
    "text_utils.seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text classification pipeline\n",
    "\n",
    "processor=text_utils.text_processor()\n",
    "train['cleaned_tweet']=train['OriginalTweet'].apply(lambda x:processor.process_text(x))\n",
    "test['cleaned_tweet']=test['OriginalTweet'].apply(lambda x:processor.process_text(x))\n",
    "train.head()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check word count distribution to identify the length of the sequence (max_len)\n",
    "lengths = train['cleaned_tweet'].apply(lambda s : len(s))\n",
    "lengths.plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenize the sentences and pad sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=configs.max_features)\n",
    "tokenizer.fit_on_texts(list(train['cleaned_tweet']))\n",
    "train_X = tokenizer.texts_to_sequences(train['cleaned_tweet'])\n",
    "test_X = tokenizer.texts_to_sequences(test['cleaned_tweet'])\n",
    "\n",
    "## Pad the sentences \n",
    "train_X = pad_sequences(train_X, maxlen=configs.maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen=configs.maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding output variable\n",
    "le = LabelEncoder()\n",
    "train_y = le.fit_transform(list(train['Sentiment']))\n",
    "test_y = le.transform(list(test['Sentiment']))\n",
    "\n",
    "# Savign label encoder for inference pipeline\n",
    "output = open('label_encoder.pkl', 'wb')\n",
    "pickle.dump(le, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the embedding matrix from glove pretrained embedding\n",
    "\n",
    "embedding_matrix = text_utils.load_glove(tokenizer.word_index,configs.max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model architecture\n",
    "\n",
    "model=model_utils.BiLSTM(configs.hidden_size,configs.num_classes,configs.dropout,configs.max_features,configs.embed_size,\n",
    "                         embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU check\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data and model configurations\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "\n",
    "# Convert train and test numpy arrays as tensors\n",
    "x_train = torch.tensor(train_X, dtype=torch.long)\n",
    "y_train = torch.tensor(train_y, dtype=torch.long)\n",
    "x_cv = torch.tensor(test_X, dtype=torch.long)\n",
    "y_cv = torch.tensor(test_y, dtype=torch.long)\n",
    "\n",
    "# Packaging features and labels together\n",
    "train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "valid = torch.utils.data.TensorDataset(x_cv, y_cv)\n",
    "\n",
    "# Loading into data loader for batch operation\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=configs.batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=configs.batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "for epoch in range(configs.n_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    avg_loss = 0  \n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        # Forward Pass\n",
    "        y_pred = model(x_batch)\n",
    "        # Compute loss\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        # Back prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "    \n",
    "    # Set model to validation configuration\n",
    "    model.eval()        \n",
    "    avg_val_loss = 0.\n",
    "    val_preds = np.zeros((len(x_cv),len(le.classes_)))\n",
    "    \n",
    "    for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "        y_pred = model(x_batch).detach()\n",
    "        avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "        # keep/store predictions\n",
    "        val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
    "    \n",
    "    # Check Accuracy\n",
    "    val_accuracy = sum(val_preds.argmax(axis=1)==test_y)/len(test_y)\n",
    "    train_loss.append(avg_loss)\n",
    "    valid_loss.append(avg_val_loss)\n",
    "    elapsed_time = time.time() - start_time \n",
    "    print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f}  \\t val_acc={:.4f}  \\t time={:.2f}s'.format(\n",
    "                epoch + 1, n_epochs, avg_loss, avg_val_loss, val_accuracy, elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model weights\n",
    "\n",
    "torch.save(model.state_dict(), './bilstm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5906cf778a79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfastapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFastAPI\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'model_utils'"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "import torch\n",
    "import model_utils\n",
    "import configs\n",
    "from pydantic import BaseModel\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "app = FastAPI(title=\"NLP tester\", description=\"API for NLP use cases\", version=\"1.0\")\n",
    "\n",
    "model = model_utils.BiLSTM(configs.hidden_size,configs.num_classes,configs.dropout,\n",
    "configs.max_features,configs.embed_size,np.zeros((configs.max_features, configs.embed_size)))\n",
    "model.load_state_dict(torch.load('./model_files/bilstm.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,json\n",
    "payload = json.dumps({\n",
    "  \"text\": 'Hello'\n",
    "})\n",
    "response = requests.put(\"http://127.0.0.1:8000/predict\",data = payload)\n",
    "data_dict = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detail': 'Method Not Allowed'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
