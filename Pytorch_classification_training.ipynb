{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import text_utils\n",
    "import model_utils\n",
    "import configs\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "import torch\n",
    "import model_utils\n",
    "import configs\n",
    "from pydantic import BaseModel\n",
    "import numpy as np\n",
    "import text_utils\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "app = FastAPI(title=\"NLP tester\", description=\"API for NLP use cases\", version=\"1.0\")\n",
    "\n",
    "model = model_utils.BiLSTM(configs.hidden_size,configs.num_classes,configs.dropout,\n",
    "configs.max_features,configs.embed_size,np.zeros((configs.max_features, configs.embed_size)))\n",
    "model.load_state_dict(torch.load('./model_files/bilstm.pt'))\n",
    "\n",
    "# Loading tokenizer\n",
    "\n",
    "# loading\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "    \n",
    "# Importing label encoder\n",
    "with open('label_encoder.pkl', 'rb') as handle:\n",
    "    le = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prediction function\n",
    "def predict_single(x):    \n",
    "    # clean the text\n",
    "    processor=text_utils.text_processor()\n",
    "    x = processor.process_text(x)\n",
    "    # tokenize\n",
    "    x = tokenizer.texts_to_sequences([x])\n",
    "    # pad\n",
    "    x = pad_sequences(x, maxlen=configs.maxlen)\n",
    "    # create dataset\n",
    "    x = torch.tensor(x, dtype=torch.long)\n",
    "\n",
    "    pred = model(x).detach()\n",
    "    pred = F.softmax(pred).cpu().numpy()\n",
    "\n",
    "    pred = pred.argmax(axis=1)\n",
    "\n",
    "    pred = le.classes_[pred]\n",
    "    return pred[0]\n",
    "\n",
    "# define the Input class\n",
    "class Input(BaseModel):\n",
    "    text : str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(text):\n",
    "    data = text\n",
    "    print(data)\n",
    "    prediction = predict_single(data).tolist()\n",
    "    return {\"prediction\": prediction}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\": \"NLP tester is bad\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pranavj\\appdata\\local\\continuum\\anaconda3\\envs\\info_surfacing\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prediction': 'Extremely Negative'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests,json\n",
    "payload = json.dumps({\n",
    "  \"text\" : \"NLP tester is bad\"\n",
    "})\n",
    "a=get_prediction(payload)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [405]>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests,json\n",
    "payload = json.dumps({\n",
    "  'text' : 'NLP tester is bad'\n",
    "})\n",
    "response = requests.put(\"http://127.0.0.1:8000/predict\",data = payload)\n",
    "#data_dict = response.json\n",
    "#data_dict\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training shape (41157, 6)\n",
      "Number of testing records (3798, 6)\n",
      "Number of unique labels in train 5\n",
      "Number of unique labels in test 5\n"
     ]
    }
   ],
   "source": [
    "# Importing data\n",
    "\n",
    "train=pd.read_csv('./Corona_NLP_train.csv',encoding='latin1')\n",
    "test=pd.read_csv('./Corona_NLP_test.csv')\n",
    "print('Number of training shape',train.shape)\n",
    "print('Number of testing records',test.shape)\n",
    "print('Number of unique labels in train',train['Sentiment'].nunique())\n",
    "print('Number of unique labels in test',test['Sentiment'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeding everything for reproducability\n",
    "text_utils.seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>tag tag tag weblink and weblink and weblink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>coronavirus australia woolworths to give elder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>me ready to go at supermarket during the covid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \\\n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral   \n",
       "1  advice Talk to your neighbours family to excha...            Positive   \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive   \n",
       "3  My food stock is not the only one which is emp...            Positive   \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative   \n",
       "\n",
       "                                       cleaned_tweet  \n",
       "0        tag tag tag weblink and weblink and weblink  \n",
       "1  advice talk to your neighbours family to excha...  \n",
       "2  coronavirus australia woolworths to give elder...  \n",
       "3  my food stock is not the only one which is emp...  \n",
       "4  me ready to go at supermarket during the covid...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text classification pipeline\n",
    "\n",
    "processor=text_utils.text_processor()\n",
    "train['cleaned_tweet']=train['OriginalTweet'].apply(lambda x:processor.process_text(x))\n",
    "test['cleaned_tweet']=test['OriginalTweet'].apply(lambda x:processor.process_text(x))\n",
    "train.head()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check word count distribution to identify the length of the sequence (max_len)\n",
    "lengths = train['cleaned_tweet'].apply(lambda s : len(s))\n",
    "lengths.plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenize the sentences and pad sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=configs.max_features)\n",
    "tokenizer.fit_on_texts(list(train['cleaned_tweet']))\n",
    "train_X = tokenizer.texts_to_sequences(train['cleaned_tweet'])\n",
    "test_X = tokenizer.texts_to_sequences(test['cleaned_tweet'])\n",
    "\n",
    "## Pad the sentences \n",
    "train_X = pad_sequences(train_X, maxlen=configs.maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen=configs.maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding output variable\n",
    "le = LabelEncoder()\n",
    "train_y = le.fit_transform(list(train['Sentiment']))\n",
    "test_y = le.transform(list(test['Sentiment']))\n",
    "\n",
    "# Savign label encoder for inference pipeline\n",
    "output = open('label_encoder.pkl', 'wb')\n",
    "pickle.dump(le, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the embedding matrix from glove pretrained embedding\n",
    "\n",
    "embedding_matrix = text_utils.load_glove(tokenizer.word_index,configs.max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model architecture\n",
    "\n",
    "model=model_utils.BiLSTM(configs.hidden_size,configs.num_classes,configs.dropout,configs.max_features,configs.embed_size,\n",
    "                         embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU check\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data and model configurations\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "\n",
    "# Convert train and test numpy arrays as tensors\n",
    "x_train = torch.tensor(train_X, dtype=torch.long)\n",
    "y_train = torch.tensor(train_y, dtype=torch.long)\n",
    "x_cv = torch.tensor(test_X, dtype=torch.long)\n",
    "y_cv = torch.tensor(test_y, dtype=torch.long)\n",
    "\n",
    "# Packaging features and labels together\n",
    "train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "valid = torch.utils.data.TensorDataset(x_cv, y_cv)\n",
    "\n",
    "# Loading into data loader for batch operation\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=configs.batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=configs.batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "for epoch in range(configs.n_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    avg_loss = 0  \n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        # Forward Pass\n",
    "        y_pred = model(x_batch)\n",
    "        # Compute loss\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        # Back prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "    \n",
    "    # Set model to validation configuration\n",
    "    model.eval()        \n",
    "    avg_val_loss = 0.\n",
    "    val_preds = np.zeros((len(x_cv),len(le.classes_)))\n",
    "    \n",
    "    for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "        y_pred = model(x_batch).detach()\n",
    "        avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "        # keep/store predictions\n",
    "        val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
    "    \n",
    "    # Check Accuracy\n",
    "    val_accuracy = sum(val_preds.argmax(axis=1)==test_y)/len(test_y)\n",
    "    train_loss.append(avg_loss)\n",
    "    valid_loss.append(avg_val_loss)\n",
    "    elapsed_time = time.time() - start_time \n",
    "    print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f}  \\t val_acc={:.4f}  \\t time={:.2f}s'.format(\n",
    "                epoch + 1, n_epochs, avg_loss, avg_val_loss, val_accuracy, elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model weights\n",
    "\n",
    "torch.save(model.state_dict(), './bilstm.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
